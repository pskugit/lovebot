{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLSv1.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D:/programming/lovebot/config.ini']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import logging\n",
    "from selenium.common.exceptions import *\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from src.tinderweb import TinderAutomator, Controller, SLEEP_MULTIPLIER\n",
    "from src.data_interface import Backlog, STATUS_CODE, STATUS_CODE_INV\n",
    "from src.gpt3 import Gpt3, Allowance\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.environ[\"LOVEBOT_CONFIG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLEEP_MULTIPLIER = int(config[\"DEFAULT\"][\"SleepTime\"])\n",
    "path_prefix = config['DEFAULT'][\"PathPrefix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('TA')\n",
    "logger.setLevel(logging.INFO)\n",
    "# create file handler which logs even debug messages\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "logging_file_name = f'logs/texter_run_{timestr}.log'\n",
    "fh = logging.FileHandler(path_prefix+logging_file_name, 'w', 'utf-8')\n",
    "fh.setLevel(logging.INFO)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TA:Remaining Tokens for today: \n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Remaining Tokens for today: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize automator\n",
    "ta = TinderAutomator(chromedata_path=config['DEFAULT']['ChromeDataPath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TA:Remaining Tokens for today: 50\n"
     ]
    }
   ],
   "source": [
    "# initialize allowance\n",
    "allowance = Allowance(path=path_prefix+\"memory/gpt_allowance.csv\")\n",
    "\n",
    "# initialize backlog\n",
    "backlog = Backlog(path=path_prefix+\"memory/backlog.csv\")\n",
    "\n",
    "# initialize Gpt3\n",
    "gpt = Gpt3(allowance)\n",
    "logger.info(\"Remaining Tokens for today: \"+str(gpt.allowance.get_tokens()))\n",
    "gpt_dryrun=False\n",
    "msg_dryrun=False\n",
    "\n",
    "min_date = pd.Timestamp.today()-pd.Timedelta(days=90)\n",
    "name_me = \"Chris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting browser with user data at D:\\programming\\lovebot\\chromedata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TA:Remaining tokens: 50\n",
      "INFO:TA:Open tasks: 184\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 1------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 new matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TA:------------------Prachi------------------\n",
      "INFO:TA:------------------Status: Running. Conversing...\n",
      "INFO:TA:::PROMPT::\n",
      "INFO:TA:This is a Tinder chat between Chris from Berlin and Prachi.\n",
      "Prachis profile says:\n",
      "üìç Visiting Berlin - here for a good time not a long time üôÉ\n",
      "Looking for someone to watch football with on Sundays üèà\n",
      "\n",
      "Chris asks a witty question relating to her profile:\n",
      "INFO:TA:::GPT::\n",
      "INFO:TA:Have you found someone to watch football with yet?\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 2------------------\n",
      "INFO:TA:------------------Amy ng------------------\n",
      "INFO:TA:------------------Status: Running. Still no reply...\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 3------------------\n",
      "INFO:TA:------------------Zoe------------------\n",
      "INFO:TA:Some error while fetching match info...\n",
      "INFO:TA:------------------Status: Erronous. ErrorCount:5\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 4------------------\n",
      "INFO:TA:------------------Raya------------------\n",
      "INFO:TA:------------------Status: Running. Still no reply...\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 5------------------\n",
      "INFO:TA:------------------Shal------------------\n",
      "INFO:TA:------------------Status: Running. Conversing...\n",
      "INFO:TA:::PROMPT::\n",
      "INFO:TA:This is a Tinder chat between Chris from Berlin and Shal.\n",
      "Chris tends to ask witty entertaining questions relating to the ongoing conversation and aims to shedule a date with Shal.\n",
      "\n",
      "Chris: \"That's really cool. I'm not too familiar with quantum physics myself, but aliens and space are always interesting topics. Have you ever seen a UFO?\"\n",
      "Chris: \"Hey Shal, how come you're not into one night stands, forward momentum, or hookups?\"\n",
      "Shal: \"Well gotta say I‚Äôm abit conservative when it comes to this stuffs since I had strict parents.\"\n",
      "Shal: \"Your bio is so appealing tho. I‚Äôm kinda Science nerd tho\"\n",
      "Chris: \"Yeah, I get that a lot. I'm glad you're into science, too. What's your favorite science fact?\"\n",
      "Shal: \"Well I‚Äôm more into the innovation stuffs, quantum physics ( don‚Äôt ask me to talk about it) aliens and space\"\n",
      "Chris:\n",
      "INFO:TA:::GPT::\n",
      "INFO:TA:That's really cool. I'm not too familiar with quantum physics myself, but aliens and space are always interesting topics. Have you ever seen a UFO?\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 6------------------\n",
      "INFO:TA:------------------Hannah------------------\n",
      "INFO:TA:------------------Status: Running. Conversing...\n",
      "INFO:TA:::PROMPT::\n",
      "INFO:TA:This is a Tinder chat between Chris from Berlin and Hannah.\n",
      "Chris tends to ask witty entertaining questions relating to the ongoing conversation and aims to shedule a date with Hannah.\n",
      "\n",
      "Chris: \"Have you ever found yourself psychoanalysing someone without meaning to?\"\n",
      "Hannah: \"Yes actually but usually only ppl that I know well\"\n",
      "Chris: \"Do you think you could do it with a stranger?\"\n",
      "Hannah: \"Not with any accuracy\"\n",
      "Hannah: \"I‚Äôve done it for someone I‚Äôve met 2-3 times when they ask or if they have glaring issues\"\n",
      "Chris: \"What do you think would be the most challenging part of trying to psychoanalyse a stranger?\"\n",
      "Hannah: \"Well that‚Äôs like asking someone to bake a cake with no eggs, flour or sugar\"\n",
      "Chris:\n",
      "INFO:TA:::GPT::\n",
      "INFO:TA:I see your point. I guess the most challenging part would be trying to figure out what makes that person tick without any prior context.\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 7------------------\n",
      "INFO:TA:------------------Mai------------------\n",
      "INFO:TA:------------------Status: Running. Still no reply...\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 8------------------\n",
      "INFO:TA:------------------Ana------------------\n",
      "INFO:TA:------------------Status: Running. Still no reply...\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 9------------------\n",
      "INFO:TA:------------------Anita------------------\n",
      "INFO:TA:------------------Status: Running. Still no reply...\n",
      "INFO:TA:-------------------------------------------------\n",
      "INFO:TA:------------------Processing Nr. 10------------------\n",
      "INFO:TA:------------------Loan------------------\n",
      "INFO:TA:------------------Status: Running. Still no reply...\n",
      "INFO:TA:Run from Mon Oct  3 21:13:21 2022\n",
      "Processed 10 matches.\n",
      "47 tokes remaining for today.\n",
      "Open conversations: 160\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "limit = 25\n",
    "no_reply_limit = 5\n",
    "\n",
    "with Controller(ta) as controller:\n",
    "    # collect matches\n",
    "    time.sleep(4)\n",
    "    tasks = ta.generate_tasklist()\n",
    "    # update backlog\n",
    "    backlog.update_with_tasks(tasks)\n",
    "    # start texting\n",
    "    run_report_header = \"\"\n",
    "    new_done = 0\n",
    "    no_reply_counter = 0\n",
    "    logger.info(\"Remaining tokens: %d\",allowance.get_tokens())\n",
    "    logger.info(\"Open tasks: %d\", sum(backlog.data.Status <= 10))\n",
    "    try:\n",
    "        for count, (id_, task) in enumerate(backlog.data[(backlog.data.Status < 10)][start:start+limit].iterrows()):\n",
    "            # todo: same loop for erronous matches plus a coounter to indicate the retry count\n",
    "            logger.info(\"-------------------------------------------------\")\n",
    "            logger.info(\"------------------Processing Nr. %d------------------\", count+1)\n",
    "            if gpt.allowance.get_tokens() <= 0:\n",
    "                logger.warning(\"Ran out of tokens...\")\n",
    "                break\n",
    "            # open task\n",
    "            ta.get(task.Link)\n",
    "            name_them = task.Name\n",
    "            logger.info(\"------------------%s------------------\",name_them)\n",
    "            time.sleep(6)\n",
    "            \n",
    "            # GET BASIC INFORMATION\n",
    "            try:\n",
    "                bio, match_date = ta.read_match_info()\n",
    "                backlog.data.loc[id_,\"ErrorCount\"] = 0\n",
    "                #update status\n",
    "                backlog.data.loc[id_,\"Status\"] = STATUS_CODE_INV[\"RUNNING\"]\n",
    "            except Exception as e:\n",
    "                #logger.info(str(e))\n",
    "                logger.info(\"Some error while fetching match info...\")\n",
    "                backlog.data.loc[id_,\"ErrorCount\"] += 1\n",
    "                errorcount= backlog.data.loc[id_,\"ErrorCount\"]\n",
    "                if errorcount > 10:\n",
    "                    backlog.data.loc[id_,\"Status\"] = STATUS_CODE_INV[\"FAILED\"]\n",
    "                else:\n",
    "                    backlog.data.loc[id_,\"Status\"] = STATUS_CODE_INV[\"ERRONOUS\"]\n",
    "                logger.info(f\"------------------Status: Erronous. ErrorCount:{errorcount}\")\n",
    "                continue\n",
    "\n",
    "            ### CHECK NACH ABBRUCHBEDINGUNGEN\n",
    "            # is the match still relevant?\n",
    "            if (match_date < min_date):\n",
    "                backlog.data.loc[id_,\"Status\"] = STATUS_CODE_INV[\"EXPIRED\"]\n",
    "                logger.info(\"------------------Status: Expired.\")\n",
    "                continue\n",
    "            # is it my turn to send a message?    \n",
    "            myturn, conversation = ta.get_conversation()\n",
    "            msg_count = len(conversation)\n",
    "            backlog.data.loc[id_,\"msg_count\"] = msg_count\n",
    "            if not myturn:\n",
    "                logger.info(\"------------------Status: Running. Still no reply...\")\n",
    "                #Todo: check if last message is older than 2days\n",
    "                #Todo: if so, set extra_shot to true \n",
    "                # else check no_reply_counter and 'continue'\n",
    "                no_reply_counter +=1\n",
    "                if no_reply_counter > no_reply_limit:\n",
    "                    break\n",
    "                continue\n",
    "            # is the conversation ready for manual control?\n",
    "            if msg_count >= 15:\n",
    "                backlog.data.loc[id_,\"Status\"] = STATUS_CODE_INV[\"DONE\"]\n",
    "                logger.info(\"------------------Status: Done. Message count reached! Yeay!\")\n",
    "                logger.info(gpt._conversation_to_body(conversation,name_them))\n",
    "                run_report_header = f\"Conversation with {name_them} is ready to be taken over! (Nr. {count+1})\\n\"\n",
    "                new_done += 1\n",
    "                continue\n",
    "\n",
    "            ### INITIATE OR CONTINUE CONVERSATION\n",
    "            logger.info(\"------------------Status: Running. Conversing...\")\n",
    "            # build prompt\n",
    "            if msg_count==0:\n",
    "                prompt = gpt.build_prompt(bio, name_them, name_me, initial=True)\n",
    "            else:\n",
    "                prompt = gpt.build_prompt(conversation, name_them, name_me, initial=False)\n",
    "            logger.info(\"::PROMPT::\")\n",
    "            logger.info(prompt)\n",
    "            # get gpt response (also updates token allowance)\n",
    "            reply = gpt.request(prompt, stop_sequences=[name_them+\":\",name_me+\":\",name_them+\" responds\", name_them+\"'s response\"], temperature=0.9, dryrun=gpt_dryrun)\n",
    "            # post processing\n",
    "            reply = reply.strip(\"\\\"\\'\")\n",
    "            logger.info(\"::GPT::\")\n",
    "            logger.info(reply)\n",
    "            ta.write_message(reply, dryrun=msg_dryrun)\n",
    "            # handled successfully\n",
    "            time.sleep(3)\n",
    "\n",
    "        # Create run report\n",
    "        run_report_base = \"Run from \"+str(time.ctime())+f\"\\nProcessed {count+1} matches.\\n{gpt.allowance.get_tokens()} tokes remaining for today.\\nOpen conversations: {len(backlog.data[backlog.data.Status <= 1])}\"\n",
    "        run_report = run_report_header + (\"\\n\" * (run_report_header != \"\")) + run_report_base\n",
    "        logger.info(run_report)\n",
    "    finally:\n",
    "        #update backlog\n",
    "        backlog.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if new_done:\n",
    "#    import yagmail\n",
    "#    yag = yagmail.SMTP(config['EMAIL']['sender'], oauth2_file=path_prefix+config['EMAIL']['OauthFilePath'])\n",
    "#    TO = config['EMAIL']['receiver']\n",
    "#    yag.send(TO, \"New Conversation finished\",run_report, attachments=['../logs/run.log'])\n",
    "#    print(run_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual = False\n",
    "if manual:\n",
    "    ta.start_browser()\n",
    "    ta.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_dryrun=False\n",
    "if manual:\n",
    "    name_them= ta.browser.find_element(By.TAG_NAME,\"h1\").text\n",
    "    # get basic information\n",
    "    bio, match_date = ta.read_match_info()\n",
    "\n",
    "    myturn, conversation = ta.get_conversation()\n",
    "    msg_count = len(conversation)\n",
    "\n",
    "    # build prompt\n",
    "    if msg_count==0:\n",
    "        prompt = gpt.build_prompt(bio, name_them, name_me, initial=True)\n",
    "    else:\n",
    "        prompt = gpt.build_prompt(conversation, name_them, name_me, initial=False, last_n=0)\n",
    "    if not myturn:\n",
    "        prompt = gpt.build_prompt(conversation, name_them, name_me, initial=False, extra_shot=True, last_n=0)\n",
    "    logger.info(\"::PROMPT::\")\n",
    "    logger.info(prompt)\n",
    "    # get gpt response\n",
    "    reply = gpt.request(prompt, stop_sequences=[name_them+\":\",name_me+\":\",name_them+\" responds\", name_them+\"'s response\"], temperature=0.7, dryrun=gpt_dryrun)\n",
    "    # post processing\n",
    "    reply = reply.strip(\"\\\"\\'\")\n",
    "    #update token allowance\n",
    "    logger.info(\"::GPT::\")\n",
    "    logger.info(reply)\n",
    "    for rep in reply.split(\"\\n\"):\n",
    "        ta.write_message(rep.strip(\"\\\"\\'\"), dryrun=msg_dryrun)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import src.gpt3\n",
    "#importlib.reload(src.gpt3)\n",
    "#from src.gpt3 import Gpt3\n",
    "#gpt = Gpt3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
